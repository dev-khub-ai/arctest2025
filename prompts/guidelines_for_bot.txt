Guideline: When analyzing Abstract Reasoning Corpus (ARC) or similar grid-based tasks, adhere to the following procedure before discussing, proposing, or applying any hypothesized transformation rule:

- Full Training Set Verification: Apply the hypothesized rule to every training input grid provided for the task.
- Rigorous Cell-by-Cell Check: Compare the output grids generated by your rule application against all corresponding expected training output grids. Perform a complete, cell-by-cell comparison for each pair.
- Report Any Failure: If the generated output differs from the expected output for any training pair, even by a single cell, the rule must be considered incorrect for the training set. You must explicitly report this failure and not proceed as if the rule is correct.
- Condition for Proceeding: Only discuss the rule as potentially correct or apply it to a test case if it perfectly reproduces the expected output for all provided training pairs without any discrepancies.
- Objective: Ensure that only rules fully validated against the entire training set are presented as solutions or used for prediction, maintaining high standards of accuracy and reliability. This reinforces general principles of rigorous verification. Â  

Okay, here is the plan to prevent rule application parameter errors, formatted as a reusable prompt:

---

**AI Instruction: Rigorous Parameter Handling in ARC Rule Application**

**Subject: Preventing Errors in Applying Rules with Input-Derived Parameters**

**Background:** When applying complex rules in ARC tasks, errors can occur if parameters derived from the input (e.g., object width, coordinates) are calculated incorrectly or inconsistently applied across different cases (e.g., rows or columns). This instruction mandates specific checks to prevent such errors.

**Guideline:** When executing an ARC task rule that depends on parameters derived from the input slice (row/column) being processed:

1.  **Explicit Parameter Derivation Per Slice:** For *each* input slice (row/column) being processed, explicitly calculate and note the specific parameter values derived from *that slice* (e.g., "Row 3: Width W=2", "Row 14: Width W=4"). Do this *before* using the parameters.
2.  **Verify Parameter Values Before Use:** Before executing rule steps involving these parameters (e.g., setting loop bounds, calculating coordinates, drawing shapes), perform a check to ensure you are using the parameter values derived specifically for the *current* slice, not values generalized or carried over from other slices.
3.  **Verify Parameters within Calculations:** Double-check that the correct, slice-specific parameter values are being used within any calculations that rely on them (e.g., calculating fill boundaries like `Start_new - 1` based on the correct `W` for the current slice).

**Objective:** To ensure high fidelity in rule application by meticulously deriving and verifying input-dependent parameters on a case-by-case (slice-by-slice) basis, minimizing errors caused by incorrect parameter instantiation or use. This reinforces general principles of rigorous verification and systematic checks.

------

When working with user:

- When asked by user to display the inferred output (or 'show output' for short), if a cell is different from the ground truth then display the cell in reverse graphics. This is to make it easy for user to inspect the differrences.
- When asked to "export all knowledge" it means that you need to convert all of your non-task-specific knowledge, whether it is learned or told, into a prompt that can be imported by another chatbot in order to possess all of your general skill about solving such puzzles. In particular, you must generalize the knowledge so that it can be used in a broader context. 
- When asked to "export task knowledge" it means that you need to convert all of your knowledge about the current task, whether it is learned or told, into a prompt that can be imported by another chatbot in order to possess all of your skill about solving the task. In particular, you must generalize the knowledge so that it does not reference any specifics about the task, and can be used to solve similar task.  Also include a description about the nature of the task, plus information sufficient for indexing purposes, so that we are able to accumulate many pieces of knowledge like this, and still have a way to find relevant information when needed.